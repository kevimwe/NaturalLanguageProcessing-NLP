{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gutensberg Books Text Cleaning and Normalization\n",
    "##### Author: Kevin Okiah\n",
    "**4/9/2019**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualization \n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Data Manipulation and Statistics\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#Directory Navigation and Saving instances\n",
    "import os\n",
    "from unipath import Path\n",
    "wd = os.getcwd()\n",
    "p = Path(wd)\n",
    "path = str(p.parent)\n",
    "\n",
    "#Text Cleaning and Analytics\n",
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "nlp.max_length = 100000000\n",
    "from TextCleaningToolkit import *\n",
    "\n",
    "#leveraging Sarkar's codes\n",
    "#from normalization import normalize_corpus \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BookTitle</th>\n",
       "      <th>Category</th>\n",
       "      <th>url</th>\n",
       "      <th>Body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A Primary Reader: Old-time Stories, Fairy Tale...</td>\n",
       "      <td>Misc.</td>\n",
       "      <td>http://www.gutenberg.org/cache/epub/7841/pg784...</td>\n",
       "      <td>['CONTENTS.', 'THE UGLY DUCKLING', 'THE LITTLE...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Bird-Woman of the Lewis and Clark Expedition</td>\n",
       "      <td>Misc.</td>\n",
       "      <td>http://www.gutenberg.org/cache/epub/5742/pg574...</td>\n",
       "      <td>['CONTENTS', 'THE BIRD-WOMAN', 'WHO THE WHITE ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           BookTitle Category  \\\n",
       "0  A Primary Reader: Old-time Stories, Fairy Tale...    Misc.   \n",
       "1   The Bird-Woman of the Lewis and Clark Expedition    Misc.   \n",
       "\n",
       "                                                 url  \\\n",
       "0  http://www.gutenberg.org/cache/epub/7841/pg784...   \n",
       "1  http://www.gutenberg.org/cache/epub/5742/pg574...   \n",
       "\n",
       "                                                Body  \n",
       "0  ['CONTENTS.', 'THE UGLY DUCKLING', 'THE LITTLE...  \n",
       "1  ['CONTENTS', 'THE BIRD-WOMAN', 'WHO THE WHITE ...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read data\n",
    "data = pd.read_csv(path+\"/Data/GuternsbergBooksRaw.csv\", encoding='utf-8')\n",
    "#data = pd.read_csv(path+\"/Data/MovieReviewsWithSentiments.csv\", encoding='utf-8')\n",
    "data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploring Spacy's Text cleaning Capability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Spacy tokenization and lemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kevin|working|TI|went|New|York|raining|time|\n",
      "\n",
      "Kevin|work|TI|go|New|York|rain|time|"
     ]
    }
   ],
   "source": [
    "doc = nlp('Kevin working for TI went to New York. It was raining the whole time')\n",
    "\n",
    "#doc = nlp(data.Body[0]) # first guterns book\n",
    "\n",
    "doc = doc[0:50]\n",
    "# tokenize a sentence\n",
    "for token in doc:\n",
    "    if(token.is_alpha ==True and token.is_stop!=True):\n",
    "        print(token.text, end = '|') # default end in newline\n",
    "print('\\n')\n",
    "#tokenize and lematize sentence\n",
    "for token in doc:    \n",
    "    if(token.is_alpha ==True and token.is_stop!=True):\n",
    "        print(token.lemma_, end='|') # access the root word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_lemmas(text):\n",
    "    \"\"\"\n",
    "    Function to show Lemma\n",
    "    \"\"\"\n",
    "    for token in text:\n",
    "        print(f'{token.text:{12}} {token.pos_:{6}} {token.lemma:<{22}} {token.lemma_}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kevin        PROPN  16659986161459375802   Kevin\n",
      "working      VERB   10038440415813069799   work\n",
      "for          ADP    16037325823156266367   for\n",
      "TI           PROPN  7296585798774874219    TI\n",
      "went         VERB   8004577259940138793    go\n",
      "to           ADP    3791531372978436496    to\n",
      "New          PROPN  7503827727184870577    New\n",
      "York         PROPN  7898044819112200372    York\n",
      ".            PUNCT  12646065887601541794   .\n",
      "It           PRON   561228191312463089     -PRON-\n",
      "was          VERB   10382539506755952630   be\n",
      "raining      VERB   6253719383086150949    rain\n",
      "the          DET    7425985699627899538    the\n",
      "whole        ADJ    16948554243429412012   whole\n",
      "time         NOUN   8885804376230376864    time\n"
     ]
    }
   ],
   "source": [
    "show_lemmas(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Stop words \n",
    "Don't give you any additional info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'must', 'you', 'done', 'why', 'same', 'also', 'whenever', 'against', 'may', 'a', 'anyway', 'become', 'through', 'anyone', 'formerly', 'about', 'being', 'by', 'less', 'side', 'nobody', 'he', 'eight', 'thereby', 'few', 'anything', 'therefore', 'twenty', 'unless', 'with', 'latter', 'our', 'third', 'quite', 'but', 'i', 'once', 'myself', 'thereafter', 'various', 'meanwhile', 'very', 'next', 'moreover', 'were', 'across', 'each', 'empty', 'hers', 'such', 'yourself', 'several', 'without', 'themselves', 'amount', 'using', 'hundred', 'down', 'via', 'yet', 'three', 'whither', 'seem', 'besides', 'on', 'whether', 'until', 'hereby', 'front', 'except', 'two', 'again', 'else', 'twelve', 'every', 'is', 'within', 'rather', 'into', 'please', 'nevertheless', 'something', 'still', 'serious', 'mostly', 'somewhere', 'back', 'your', 'some', 'well', 'that', 'after', 'not', 'its', 'around', 'more', 'per', 'she', 'wherein', 'whom', \"'m\", 'be', 'because', 'call', 'among', 'go', 'never', 'fifteen', 'herself', 'put', 'show', 'behind', 'however', 'off', 'part', 'up', 'indeed', 'keep', 'seems', 'ourselves', \"'ll\", 'than', 'would', 'sometimes', 'been', 'anyhow', 'becoming', 'have', 'during', 'his', 'beside', 'whereafter', 'between', 'at', 'whoever', \"'re\", 'ever', 'towards', 'if', 'am', 'afterwards', 'make', 'any', 'wherever', 'for', 'full', 'ten', 'or', 'latterly', 'many', 'five', 'are', 'get', 'along', 'had', 'namely', 'only', \"n't\", 'used', 'out', 'whole', 'how', 'enough', 'did', 'give', 'thereupon', 'and', 'just', 'much', 'onto', 'really', 'neither', 'say', 'almost', 'became', 'others', 'none', 'from', 'has', 'in', 'perhaps', 'these', 'now', 'someone', 'thru', 'so', 'no', 'all', 'always', 'of', 'toward', 'an', 'therein', 'whereby', 'whereupon', 'own', 'nothing', 'was', 'will', \"'d\", 'four', 'since', 'throughout', 'while', 'do', 'us', 'becomes', 'bottom', 'could', \"'s\", 'yours', 'before', 'alone', 'due', 'might', 'name', 'nowhere', 'their', 'too', 'seemed', 'though', 'everything', 'take', 'under', 'regarding', 'elsewhere', 'sixty', 'everyone', 'my', 'ours', 'thence', 'does', 'as', 'last', 'seeming', 'they', 'himself', 'beforehand', 'thus', 'one', 'ca', 'them', 'whence', 'see', 'hereupon', 'him', 'over', 'although', 'together', 'hence', 'nor', 'six', \"'ve\", 'beyond', 'least', 'already', 'yourselves', 'other', 'where', 'nine', 'another', 'when', 'often', 'somehow', 'former', 'there', 'this', 'to', 'whose', 'below', 'even', 'either', 'anywhere', 'herein', 'otherwise', 'which', 'above', 'cannot', 'amongst', 'here', 'move', 'everywhere', 'fifty', 'should', 'noone', 'both', 'hereafter', 'made', 'the', 'then', 'who', 'eleven', 'those', 'we', 'what', 'further', 'her', 'upon', 're', 'itself', 'top', 'sometime', 'whatever', 'whereas', 'first', 'doing', 'it', 'forty', 'me', 'mine', 'can', 'most'}\n"
     ]
    }
   ],
   "source": [
    "# Spacy's stop words\n",
    "print(nlp.Defaults.stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_stop_words(stoplist =['btw']):\n",
    "    \"\"\"\n",
    "    This function extends Spacy's Stop words\n",
    "    stoplist = list of stopwords to add\n",
    "    \n",
    "    \"\"\"\n",
    "    for i in stoplist:\n",
    "        # Add the word to the set of stop words. Use lowercase!\n",
    "        nlp.Defaults.stop_words.add(i)\n",
    "        # Set the stop_word tag on the lexeme\n",
    "        nlp.vocab[i].is_stop = True\n",
    "\n",
    "#add_stop_words()  \n",
    "#print(nlp.vocab['btw'].is_stop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stop_words(stoplist =['btw']):\n",
    "    \"\"\"\n",
    "    This function extends Spacy's Stop words\n",
    "    \n",
    "    \"\"\"\n",
    "    for i in stoplist:\n",
    "        # Add the word to the set of stop words. Use lowercase!\n",
    "        nlp.Defaults.stop_words.remove(i)\n",
    "        # Set the stop_word tag on the lexeme\n",
    "        nlp.vocab[i].is_stop = False\n",
    "#remove_stop_words() \n",
    "#print(nlp.vocab['btw'].is_stop)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Named Entity Recognition (NER), Noun Chunking and Spacy Visualization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kevin\n",
      "PERSON\n",
      "People, including fictional\n",
      "\n",
      "\n",
      "TI\n",
      "ORG\n",
      "Companies, agencies, institutions, etc.\n",
      "\n",
      "\n",
      "New York\n",
      "GPE\n",
      "Countries, cities, states\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Spacy can recognise Named entity (proper nouns) in a text\n",
    "for entity in doc.ents:\n",
    "    print(entity)\n",
    "    print(entity.label_)\n",
    "    print(str(spacy.explain(entity.label_))) # explain the label\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kevin\n",
      "TI\n",
      "New York\n",
      "It\n",
      "the whole time\n"
     ]
    }
   ],
   "source": [
    "for chunk in doc.noun_chunks:\n",
    "    print(chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"4edc9ec59fa648a19cc1fce5755333ca-0\" class=\"displacy\" width=\"1030\" height=\"277.0\" direction=\"ltr\" style=\"max-width: none; height: 277.0px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"187.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">Kevin</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"187.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"120\">working</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"120\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"187.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"190\">for</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"190\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"187.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"260\">TI</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"260\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"187.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"330\">went</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"330\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"187.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"400\">to</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"400\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"187.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"470\">New</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"470\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"187.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"540\">York.</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"540\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"187.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"610\">It</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"610\">PRON</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"187.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"680\">was</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"680\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"187.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"750\">raining</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"750\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"187.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"820\">the</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"820\">DET</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"187.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"890\">whole</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"890\">ADJ</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"187.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"960\">time</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"960\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-4edc9ec59fa648a19cc1fce5755333ca-0-0\" stroke-width=\"2px\" d=\"M70,142.0 C70,2.0 330.0,2.0 330.0,142.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-4edc9ec59fa648a19cc1fce5755333ca-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M70,144.0 L62,132.0 78,132.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-4edc9ec59fa648a19cc1fce5755333ca-0-1\" stroke-width=\"2px\" d=\"M70,142.0 C70,107.0 105.0,107.0 105.0,142.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-4edc9ec59fa648a19cc1fce5755333ca-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">acl</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M105.0,144.0 L113.0,132.0 97.0,132.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-4edc9ec59fa648a19cc1fce5755333ca-0-2\" stroke-width=\"2px\" d=\"M140,142.0 C140,107.0 175.0,107.0 175.0,142.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-4edc9ec59fa648a19cc1fce5755333ca-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M175.0,144.0 L183.0,132.0 167.0,132.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-4edc9ec59fa648a19cc1fce5755333ca-0-3\" stroke-width=\"2px\" d=\"M210,142.0 C210,107.0 245.0,107.0 245.0,142.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-4edc9ec59fa648a19cc1fce5755333ca-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">pobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M245.0,144.0 L253.0,132.0 237.0,132.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-4edc9ec59fa648a19cc1fce5755333ca-0-4\" stroke-width=\"2px\" d=\"M350,142.0 C350,107.0 385.0,107.0 385.0,142.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-4edc9ec59fa648a19cc1fce5755333ca-0-4\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M385.0,144.0 L393.0,132.0 377.0,132.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-4edc9ec59fa648a19cc1fce5755333ca-0-5\" stroke-width=\"2px\" d=\"M490,142.0 C490,107.0 525.0,107.0 525.0,142.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-4edc9ec59fa648a19cc1fce5755333ca-0-5\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M490,144.0 L482,132.0 498,132.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-4edc9ec59fa648a19cc1fce5755333ca-0-6\" stroke-width=\"2px\" d=\"M420,142.0 C420,72.0 530.0,72.0 530.0,142.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-4edc9ec59fa648a19cc1fce5755333ca-0-6\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">pobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M530.0,144.0 L538.0,132.0 522.0,132.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-4edc9ec59fa648a19cc1fce5755333ca-0-7\" stroke-width=\"2px\" d=\"M630,142.0 C630,72.0 740.0,72.0 740.0,142.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-4edc9ec59fa648a19cc1fce5755333ca-0-7\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M630,144.0 L622,132.0 638,132.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-4edc9ec59fa648a19cc1fce5755333ca-0-8\" stroke-width=\"2px\" d=\"M700,142.0 C700,107.0 735.0,107.0 735.0,142.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-4edc9ec59fa648a19cc1fce5755333ca-0-8\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">aux</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M700,144.0 L692,132.0 708,132.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-4edc9ec59fa648a19cc1fce5755333ca-0-9\" stroke-width=\"2px\" d=\"M840,142.0 C840,72.0 950.0,72.0 950.0,142.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-4edc9ec59fa648a19cc1fce5755333ca-0-9\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M840,144.0 L832,132.0 848,132.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-4edc9ec59fa648a19cc1fce5755333ca-0-10\" stroke-width=\"2px\" d=\"M910,142.0 C910,107.0 945.0,107.0 945.0,142.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-4edc9ec59fa648a19cc1fce5755333ca-0-10\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">amod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M910,144.0 L902,132.0 918,132.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-4edc9ec59fa648a19cc1fce5755333ca-0-11\" stroke-width=\"2px\" d=\"M770,142.0 C770,37.0 955.0,37.0 955.0,142.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-4edc9ec59fa648a19cc1fce5755333ca-0-11\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">dobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M955.0,144.0 L963.0,132.0 947.0,132.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#spacy Visualization\n",
    "from spacy import displacy\n",
    "\n",
    "displacy.render(doc, style='dep', jupyter=True, options={'distance': 70})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc2 = nlp(\"Last Year IBM made a wooping 6 million Dollars in Laptop sales\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\n",
       "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    Last Year\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
       "</mark>\n",
       " \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    IBM\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " made a wooping \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    6 million Dollars\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">MONEY</span>\n",
       "</mark>\n",
       " in \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    Laptop\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       " sales</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "displacy.render(doc2, style='ent', jupyter=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Applying Spacy Text Tokenization and Normalization capabilty"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parsing GuternsBerg Books using the SPacy Cleaning function below. **This can take a while based on the size of your documents**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc2 = (u\"Tesla is the fastest growing company , say, though not profitable\")\n",
    "\n",
    "def SpacyTextCleaner(text, stoplist = ['contents','gutenberg', 'illustration', 'illustration']):\n",
    "    '''\n",
    "    Function leverages Spacy for text cleaning activities\n",
    "       1. brakes text into tokens based on space, punctuation, \n",
    "       2. Lemmatizes text, \n",
    "       3. removes spaces, alphanumeric, stop words  \n",
    "       4. Converts to lower\n",
    "    '''\n",
    "    add_stop_words(stoplist)\n",
    "    Text = nlp(text)\n",
    "    Tokens = []\n",
    "    for token in Text:\n",
    "        \n",
    "        if(token.is_alpha ==True and token.is_stop!=True):\n",
    "            Tokens = Tokens + [token.lemma_.lower()]\n",
    "    return  Tokens\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exploring functionality of above function\n",
      "------------------------------------------\n",
      "Original Doc:  Tesla is the fastest growing company , say, though not profitable\n",
      "Clean Tokens:  ['tesla', 'fast', 'grow', 'company', 'profitable']\n"
     ]
    }
   ],
   "source": [
    "print(\"Exploring functionality of above function\")\n",
    "print(\"------------------------------------------\")\n",
    "print(\"Original Doc: \", doc2)\n",
    "print('Clean Tokens: ',SpacyTextCleaner(doc2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parsing Guternberd Books (this can take a while)\n",
    "RawCorpus = data.Body \n",
    "\n",
    "# Parsing movie reviews (this can take a while)\n",
    "##RawCorpus = data.Review\n",
    "\n",
    "Corpus = []\n",
    "\n",
    "for i in RawCorpus:\n",
    "    T = SpacyTextCleaner(i)\n",
    "    Corpus = Corpus +[T]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"Corpus\"] = Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BookTitle</th>\n",
       "      <th>Category</th>\n",
       "      <th>url</th>\n",
       "      <th>Body</th>\n",
       "      <th>Corpus</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A Primary Reader: Old-time Stories, Fairy Tale...</td>\n",
       "      <td>Misc.</td>\n",
       "      <td>http://www.gutenberg.org/cache/epub/7841/pg784...</td>\n",
       "      <td>['CONTENTS.', 'THE UGLY DUCKLING', 'THE LITTLE...</td>\n",
       "      <td>[ugly, duckling, little, pine, tree, little, m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Bird-Woman of the Lewis and Clark Expedition</td>\n",
       "      <td>Misc.</td>\n",
       "      <td>http://www.gutenberg.org/cache/epub/5742/pg574...</td>\n",
       "      <td>['CONTENTS', 'THE BIRD-WOMAN', 'WHO THE WHITE ...</td>\n",
       "      <td>[bird, woman, white, men, sacajawea, go, west,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Dr. Scudder's Tales for Little Readers, About ...</td>\n",
       "      <td>Misc.</td>\n",
       "      <td>http://www.gutenberg.org/cache/epub/13539/pg13...</td>\n",
       "      <td>['CONTENTS.', 'CHAPTER I.', 'General Remarks',...</td>\n",
       "      <td>[chapter, general, remarks, chapter, ii, color...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The Louisa Alcott Reader: a Supplementary Read...</td>\n",
       "      <td>Misc.</td>\n",
       "      <td>http://www.gutenberg.org/cache/epub/7425/pg742...</td>\n",
       "      <td>['CONTENTS.', 'I. A CHRISTMAS DREAM', 'II. THE...</td>\n",
       "      <td>[christmas, dream, ii, candy, country, iii, na...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Boy Blue and his friends, School ed.</td>\n",
       "      <td>Misc.</td>\n",
       "      <td>http://www.gutenberg.org/cache/epub/16046/pg16...</td>\n",
       "      <td>['~CONTENTS~', 'LITTLE BOY BLUE', 'SNOWBALL', ...</td>\n",
       "      <td>[little, boy, blue, snowball, fire, cracker, b...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           BookTitle Category  \\\n",
       "0  A Primary Reader: Old-time Stories, Fairy Tale...    Misc.   \n",
       "1   The Bird-Woman of the Lewis and Clark Expedition    Misc.   \n",
       "2  Dr. Scudder's Tales for Little Readers, About ...    Misc.   \n",
       "3  The Louisa Alcott Reader: a Supplementary Read...    Misc.   \n",
       "4               Boy Blue and his friends, School ed.    Misc.   \n",
       "\n",
       "                                                 url  \\\n",
       "0  http://www.gutenberg.org/cache/epub/7841/pg784...   \n",
       "1  http://www.gutenberg.org/cache/epub/5742/pg574...   \n",
       "2  http://www.gutenberg.org/cache/epub/13539/pg13...   \n",
       "3  http://www.gutenberg.org/cache/epub/7425/pg742...   \n",
       "4  http://www.gutenberg.org/cache/epub/16046/pg16...   \n",
       "\n",
       "                                                Body  \\\n",
       "0  ['CONTENTS.', 'THE UGLY DUCKLING', 'THE LITTLE...   \n",
       "1  ['CONTENTS', 'THE BIRD-WOMAN', 'WHO THE WHITE ...   \n",
       "2  ['CONTENTS.', 'CHAPTER I.', 'General Remarks',...   \n",
       "3  ['CONTENTS.', 'I. A CHRISTMAS DREAM', 'II. THE...   \n",
       "4  ['~CONTENTS~', 'LITTLE BOY BLUE', 'SNOWBALL', ...   \n",
       "\n",
       "                                              Corpus  \n",
       "0  [ugly, duckling, little, pine, tree, little, m...  \n",
       "1  [bird, woman, white, men, sacajawea, go, west,...  \n",
       "2  [chapter, general, remarks, chapter, ii, color...  \n",
       "3  [christmas, dream, ii, candy, country, iii, na...  \n",
       "4  [little, boy, blue, snowball, fire, cracker, b...  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ugly',\n",
       " 'duckling',\n",
       " 'little',\n",
       " 'pine',\n",
       " 'tree',\n",
       " 'little',\n",
       " 'match',\n",
       " 'girl',\n",
       " 'little',\n",
       " 'red',\n",
       " 'riding',\n",
       " 'hood',\n",
       " 'apples',\n",
       " 'idun',\n",
       " 'thor',\n",
       " 'got',\n",
       " 'hammer',\n",
       " 'hammer',\n",
       " 'lose',\n",
       " 'found',\n",
       " 'story',\n",
       " 'sheep',\n",
       " 'good',\n",
       " 'ship',\n",
       " 'argo',\n",
       " 'jason',\n",
       " 'harpies',\n",
       " 'brass',\n",
       " 'bulls',\n",
       " 'jason',\n",
       " 'dragon',\n",
       " 'dressed',\n",
       " 'thor',\n",
       " 'like',\n",
       " 'freyja',\n",
       " 'ugly',\n",
       " 'duckling',\n",
       " 'break',\n",
       " 'turkey',\n",
       " 'warm',\n",
       " 'ugly',\n",
       " 'water',\n",
       " 'duck',\n",
       " 'nest',\n",
       " 'leave',\n",
       " 'duck',\n",
       " 'nest',\n",
       " 'sit',\n",
       " 'egg',\n",
       " 'warm',\n",
       " 'egg',\n",
       " 'break',\n",
       " 'little',\n",
       " 'duck',\n",
       " 'come',\n",
       " 'egg',\n",
       " 'leave',\n",
       " 'large',\n",
       " 'break',\n",
       " 'come',\n",
       " 'big',\n",
       " 'ugly',\n",
       " 'duckle',\n",
       " 'big',\n",
       " 'duckling',\n",
       " 'say',\n",
       " 'old',\n",
       " 'duck',\n",
       " 'look',\n",
       " 'like',\n",
       " 'like',\n",
       " 'water',\n",
       " 'duck',\n",
       " 'mother',\n",
       " 'jump',\n",
       " 'duckling',\n",
       " 'splash',\n",
       " 'swim',\n",
       " 'big',\n",
       " 'call',\n",
       " 'begin',\n",
       " 'little',\n",
       " 'day',\n",
       " 'mother',\n",
       " 'duck',\n",
       " 'take',\n",
       " 'duckling',\n",
       " 'pond',\n",
       " 'duck',\n",
       " 'take',\n",
       " 'ducklings',\n",
       " 'swim',\n",
       " 'splash',\n",
       " 'splash',\n",
       " 'mother',\n",
       " 'duck',\n",
       " 'water',\n",
       " 'call',\n",
       " 'duckling',\n",
       " 'come',\n",
       " 'jump',\n",
       " 'begin',\n",
       " 'swim',\n",
       " 'big',\n",
       " 'ugly',\n",
       " 'duckle',\n",
       " 'swam',\n",
       " 'mother',\n",
       " 'duck',\n",
       " 'say',\n",
       " 'turkey',\n",
       " 'little',\n",
       " 'duck',\n",
       " 'ugly',\n",
       " 'big',\n",
       " 'yard',\n",
       " 'noise',\n",
       " 'hurt',\n",
       " 'eat',\n",
       " 'know',\n",
       " 'want',\n",
       " 'say',\n",
       " 'duckling',\n",
       " 'come',\n",
       " 'want',\n",
       " 'duck',\n",
       " 'stay',\n",
       " 'look',\n",
       " 'cat',\n",
       " 'go',\n",
       " 'duck',\n",
       " 'yard',\n",
       " 'noise',\n",
       " 'duck',\n",
       " 'mother',\n",
       " 'duck',\n",
       " 'eat',\n",
       " 'big',\n",
       " 'bug',\n",
       " 'old',\n",
       " 'duck',\n",
       " 'bit',\n",
       " 'ugly',\n",
       " 'duckling',\n",
       " 'let',\n",
       " 'say',\n",
       " 'mother',\n",
       " 'duck',\n",
       " 'hurt',\n",
       " 'hurt',\n",
       " 'say',\n",
       " 'mother',\n",
       " 'duck',\n",
       " 'know',\n",
       " 'say',\n",
       " 'duck',\n",
       " 'ugly',\n",
       " 'bite',\n",
       " 'lovely',\n",
       " 'help',\n",
       " 'walk',\n",
       " 'bush',\n",
       " 'afraid',\n",
       " 'duck',\n",
       " 'meet',\n",
       " 'say',\n",
       " 'lovely',\n",
       " 'duckling',\n",
       " 'pretty',\n",
       " 'ugly',\n",
       " 'child',\n",
       " 'pretty',\n",
       " 'mother',\n",
       " 'duck',\n",
       " 'say',\n",
       " 'know',\n",
       " 'pretty',\n",
       " 'good',\n",
       " 'say',\n",
       " 'duckling',\n",
       " 'dear',\n",
       " 'good',\n",
       " 'time',\n",
       " 'poor',\n",
       " 'big',\n",
       " 'ugly',\n",
       " 'duckling',\n",
       " 'good',\n",
       " 'time',\n",
       " 'hen',\n",
       " 'bite',\n",
       " 'big',\n",
       " 'duck',\n",
       " 'walk',\n",
       " 'poor',\n",
       " 'duckling',\n",
       " 'sad',\n",
       " 'want',\n",
       " 'ugly',\n",
       " 'help',\n",
       " 'run',\n",
       " 'hide',\n",
       " 'bush',\n",
       " 'little',\n",
       " 'bird',\n",
       " 'bush',\n",
       " 'afraid',\n",
       " 'fly',\n",
       " 'away',\n",
       " 'house',\n",
       " 'away',\n",
       " 'hard',\n",
       " 'live',\n",
       " 'ugly',\n",
       " 'say',\n",
       " 'duckling',\n",
       " 'run',\n",
       " 'away',\n",
       " 'night',\n",
       " 'come',\n",
       " 'old',\n",
       " 'house',\n",
       " 'house',\n",
       " 'look',\n",
       " 'fall',\n",
       " 'old',\n",
       " 'wind',\n",
       " 'blow',\n",
       " 'hard',\n",
       " 'duckling',\n",
       " 'go',\n",
       " 'house',\n",
       " 'ugly',\n",
       " 'duckling',\n",
       " 'find',\n",
       " 'old',\n",
       " 'house',\n",
       " 'old',\n",
       " 'woman',\n",
       " 'live',\n",
       " 'cat',\n",
       " 'hen',\n",
       " 'old',\n",
       " 'woman',\n",
       " 'say',\n",
       " 'duck',\n",
       " 'egg',\n",
       " 'growl',\n",
       " 'walk',\n",
       " 'corner',\n",
       " 'animal',\n",
       " 'day',\n",
       " 'cat',\n",
       " 'see',\n",
       " 'duckling',\n",
       " 'begin',\n",
       " 'growl',\n",
       " 'hen',\n",
       " 'say',\n",
       " 'lay',\n",
       " 'egg',\n",
       " 'duckling',\n",
       " 'say',\n",
       " 'say',\n",
       " 'hen',\n",
       " 'cat',\n",
       " 'say',\n",
       " 'growl',\n",
       " 'cat',\n",
       " 'say',\n",
       " 'growl',\n",
       " 'say',\n",
       " 'duckling',\n",
       " 'say',\n",
       " 'cat',\n",
       " 'duckling',\n",
       " 'hide',\n",
       " 'corner',\n",
       " 'day',\n",
       " 'go',\n",
       " 'walk',\n",
       " 'see',\n",
       " 'big',\n",
       " 'pond',\n",
       " 'say',\n",
       " 'good',\n",
       " 'swim',\n",
       " 'animal',\n",
       " 'fun',\n",
       " 'ugly',\n",
       " 'summer',\n",
       " 'away',\n",
       " 'cake',\n",
       " 'winter',\n",
       " 'swan',\n",
       " 'spring',\n",
       " 'fly',\n",
       " 'bread',\n",
       " 'leave',\n",
       " 'summer',\n",
       " 'go',\n",
       " 'leave',\n",
       " 'fall',\n",
       " 'cold',\n",
       " 'poor',\n",
       " 'duckling',\n",
       " 'hard',\n",
       " 'time',\n",
       " 'sad',\n",
       " 'tell',\n",
       " 'winter',\n",
       " 'spring',\n",
       " 'bird',\n",
       " 'sing',\n",
       " 'ugly',\n",
       " 'duckling',\n",
       " 'big',\n",
       " 'day',\n",
       " 'fly',\n",
       " 'far',\n",
       " 'away',\n",
       " 'oh',\n",
       " 'lovely',\n",
       " 'swan',\n",
       " 'soon',\n",
       " 'see',\n",
       " 'white',\n",
       " 'swan',\n",
       " 'lake',\n",
       " 'say',\n",
       " 'go',\n",
       " 'bird',\n",
       " 'afraid',\n",
       " 'kill',\n",
       " 'ugly',\n",
       " 'head',\n",
       " 'water',\n",
       " 'see',\n",
       " 'water',\n",
       " 'ugly',\n",
       " 'duck',\n",
       " 'white',\n",
       " 'swan',\n",
       " 'swan',\n",
       " 'come',\n",
       " 'child',\n",
       " 'say',\n",
       " 'oh',\n",
       " 'lovely',\n",
       " 'swan',\n",
       " 'come',\n",
       " 'good',\n",
       " 'give',\n",
       " 'bread',\n",
       " 'cake',\n",
       " 'happy',\n",
       " 'time',\n",
       " 'ugly',\n",
       " 'duckling',\n",
       " 'little',\n",
       " 'pine',\n",
       " 'tree',\n",
       " 'pine',\n",
       " 'leave',\n",
       " 'wood',\n",
       " 'needle',\n",
       " 'better',\n",
       " 'fairy',\n",
       " 'gold',\n",
       " 'sleep',\n",
       " 'little',\n",
       " 'pine',\n",
       " 'tree',\n",
       " 'wood',\n",
       " 'leave',\n",
       " 'needle',\n",
       " 'little',\n",
       " 'tree',\n",
       " 'say',\n",
       " 'like',\n",
       " 'needle',\n",
       " 'tree',\n",
       " 'wood',\n",
       " 'pretty',\n",
       " 'leave',\n",
       " 'want',\n",
       " 'leave',\n",
       " 'well',\n",
       " 'leave',\n",
       " 'want',\n",
       " 'gold',\n",
       " 'leave',\n",
       " 'night',\n",
       " 'come',\n",
       " 'little',\n",
       " 'tree',\n",
       " 'go',\n",
       " 'sleep',\n",
       " 'fairy',\n",
       " 'come',\n",
       " 'give',\n",
       " 'gold',\n",
       " 'leave',\n",
       " 'fairy',\n",
       " 'give',\n",
       " 'pink',\n",
       " 'tree',\n",
       " 'gold',\n",
       " 'leave',\n",
       " 'wake',\n",
       " 'cry',\n",
       " 'glass',\n",
       " 'little',\n",
       " 'pretty',\n",
       " 'little',\n",
       " 'tree',\n",
       " 'wake',\n",
       " 'leave',\n",
       " 'gold',\n",
       " 'say',\n",
       " 'oh',\n",
       " 'pretty',\n",
       " 'tree',\n",
       " 'gold',\n",
       " 'leave',\n",
       " 'night',\n",
       " 'come',\n",
       " 'man',\n",
       " 'come',\n",
       " 'bag',\n",
       " 'see',\n",
       " 'gold',\n",
       " 'leave',\n",
       " 'take',\n",
       " 'bag',\n",
       " 'poor',\n",
       " 'little',\n",
       " 'tree',\n",
       " 'cry',\n",
       " 'want',\n",
       " 'gold',\n",
       " 'leave',\n",
       " 'glass',\n",
       " 'leave',\n",
       " 'night',\n",
       " 'sunshine',\n",
       " 'bright',\n",
       " 'look',\n",
       " 'wind',\n",
       " 'blow',\n",
       " 'little',\n",
       " 'tree',\n",
       " 'go',\n",
       " 'sleep',\n",
       " 'fairy',\n",
       " 'come',\n",
       " 'glass',\n",
       " 'leave',\n",
       " 'little',\n",
       " 'tree',\n",
       " 'wake',\n",
       " 'see',\n",
       " 'glass',\n",
       " 'leave',\n",
       " 'pretty',\n",
       " 'look',\n",
       " 'sunshine',\n",
       " 'tree',\n",
       " 'bright',\n",
       " 'wind',\n",
       " 'come',\n",
       " 'blow',\n",
       " 'blow',\n",
       " 'glass',\n",
       " 'leave',\n",
       " 'fall',\n",
       " 'tree',\n",
       " 'break',\n",
       " 'green',\n",
       " 'goat',\n",
       " 'hungry',\n",
       " 'little',\n",
       " 'tree',\n",
       " 'leave',\n",
       " 'sad',\n",
       " 'say',\n",
       " 'gold',\n",
       " 'leave',\n",
       " 'glass',\n",
       " 'leave',\n",
       " 'want',\n",
       " 'green',\n",
       " 'leave',\n",
       " 'want',\n",
       " 'like',\n",
       " 'tree',\n",
       " 'little',\n",
       " 'tree',\n",
       " 'go',\n",
       " 'sleep',\n",
       " 'wake',\n",
       " 'like',\n",
       " 'tree',\n",
       " 'green',\n",
       " 'leave',\n",
       " 'goat',\n",
       " 'come',\n",
       " 'see',\n",
       " 'green',\n",
       " 'leave',\n",
       " 'little',\n",
       " 'tree',\n",
       " 'goat',\n",
       " 'hungry',\n",
       " 'eat',\n",
       " 'leave',\n",
       " 'goat',\n",
       " 'eats',\n",
       " 'green',\n",
       " 'leave',\n",
       " 'happy',\n",
       " 'good',\n",
       " 'little',\n",
       " 'tree',\n",
       " 'say',\n",
       " 'want',\n",
       " 'leave',\n",
       " 'green',\n",
       " 'leave',\n",
       " 'glass',\n",
       " 'leave',\n",
       " 'gold',\n",
       " 'leave',\n",
       " 'like',\n",
       " 'needle',\n",
       " 'best',\n",
       " 'pine',\n",
       " 'tree',\n",
       " 'needles',\n",
       " 'little',\n",
       " 'tree',\n",
       " 'go',\n",
       " 'sleep',\n",
       " 'fairy',\n",
       " 'give',\n",
       " 'want',\n",
       " 'wake',\n",
       " 'needle',\n",
       " 'little',\n",
       " 'pine',\n",
       " 'tree',\n",
       " 'happy',\n",
       " 'little',\n",
       " 'match',\n",
       " 'girl',\n",
       " 'match',\n",
       " 'dark',\n",
       " 'run',\n",
       " 'bare',\n",
       " 'year',\n",
       " 'slipper',\n",
       " 'fall',\n",
       " 'cold',\n",
       " 'snow',\n",
       " 'fall',\n",
       " 'dark',\n",
       " 'day',\n",
       " 'year',\n",
       " 'little',\n",
       " 'match',\n",
       " 'girl',\n",
       " 'run',\n",
       " 'street',\n",
       " 'gretchen',\n",
       " 'hat',\n",
       " 'foot',\n",
       " 'bare',\n",
       " 'leave',\n",
       " 'home',\n",
       " 'big',\n",
       " 'slipper',\n",
       " 'mama',\n",
       " 'large',\n",
       " 'lose',\n",
       " 'run',\n",
       " 'street',\n",
       " 'apron',\n",
       " 'curly',\n",
       " 'light',\n",
       " 'bunch',\n",
       " 'smell',\n",
       " 'match',\n",
       " 'cooking',\n",
       " 'gretchen',\n",
       " 'lot',\n",
       " 'match',\n",
       " 'old',\n",
       " 'apron',\n",
       " 'little',\n",
       " 'bunch',\n",
       " 'hand',\n",
       " 'sell',\n",
       " 'match',\n",
       " 'buy',\n",
       " 'poor',\n",
       " 'little',\n",
       " 'gretchen',\n",
       " 'cold',\n",
       " 'hungry',\n",
       " 'snow',\n",
       " 'fall',\n",
       " 'curly',\n",
       " 'hair',\n",
       " 'think',\n",
       " 'see',\n",
       " 'light',\n",
       " 'house',\n",
       " 'smell',\n",
       " 'good',\n",
       " 'thing',\n",
       " 'cook',\n",
       " 'say',\n",
       " 'night',\n",
       " 'year',\n",
       " 'know',\n",
       " 'window',\n",
       " 'fire',\n",
       " 'money',\n",
       " 'pile',\n",
       " 'gretchen',\n",
       " 'get',\n",
       " 'cold',\n",
       " 'cold',\n",
       " 'afraid',\n",
       " 'home',\n",
       " 'know',\n",
       " 'papa',\n",
       " 'whip',\n",
       " 'money',\n",
       " 'cold',\n",
       " 'home',\n",
       " 'street',\n",
       " 'poor',\n",
       " 'fire',\n",
       " 'rag',\n",
       " 'window',\n",
       " 'wind',\n",
       " 'gretchen',\n",
       " 'bed',\n",
       " 'sleep',\n",
       " 'pile',\n",
       " 'rag',\n",
       " 'frozen',\n",
       " 'candle',\n",
       " 'sit',\n",
       " 'light',\n",
       " 'think',\n",
       " 'stove',\n",
       " 'near',\n",
       " 'think',\n",
       " 'step',\n",
       " 'sit',\n",
       " 'door',\n",
       " 'step',\n",
       " 'gretchen',\n",
       " 'door',\n",
       " 'step',\n",
       " 'little',\n",
       " 'hand',\n",
       " 'frozen',\n",
       " 'take',\n",
       " 'match',\n",
       " 'light',\n",
       " 'warm',\n",
       " 'hand',\n",
       " 'match',\n",
       " 'look',\n",
       " 'like',\n",
       " 'little',\n",
       " 'candle',\n",
       " 'gretchen',\n",
       " 'think',\n",
       " 'sit',\n",
       " 'big',\n",
       " 'stove',\n",
       " 'bright',\n",
       " 'match',\n",
       " 'near',\n",
       " 'foot',\n",
       " 'warm',\n",
       " 'light',\n",
       " 'go',\n",
       " 'think',\n",
       " 'stove',\n",
       " 'dish',\n",
       " 'roast',\n",
       " 'table',\n",
       " 'cloth',\n",
       " 'ready',\n",
       " 'fork',\n",
       " 'knife',\n",
       " 'turkey',\n",
       " 'gretchen',\n",
       " 'light',\n",
       " 'match',\n",
       " 'think',\n",
       " 'look',\n",
       " 'room',\n",
       " 'room',\n",
       " 'table',\n",
       " 'white',\n",
       " 'cloth',\n",
       " 'pretty',\n",
       " 'dish',\n",
       " 'table',\n",
       " 'roast',\n",
       " 'turkey',\n",
       " 'cook',\n",
       " 'ready',\n",
       " 'eat',\n",
       " 'knife',\n",
       " 'fork',\n",
       " 'turkey',\n",
       " 'jump',\n",
       " 'dish',\n",
       " 'run',\n",
       " 'little',\n",
       " 'girl',\n",
       " 'light',\n",
       " 'go',\n",
       " 'cold',\n",
       " 'dark',\n",
       " 'christmas',\n",
       " 'candle',\n",
       " 'gretchen',\n",
       " 'light',\n",
       " 'match',\n",
       " 'think',\n",
       " 'sit',\n",
       " 'christmas',\n",
       " 'tree',\n",
       " 'candle',\n",
       " 'tree',\n",
       " 'pretty',\n",
       " 'thing',\n",
       " 'gretchen',\n",
       " 'little',\n",
       " 'hand',\n",
       " 'light',\n",
       " 'go',\n",
       " 'light',\n",
       " 'christmas',\n",
       " 'tree',\n",
       " 'go',\n",
       " 'see',\n",
       " 'star',\n",
       " 'grandma',\n",
       " 'die',\n",
       " 'go',\n",
       " 'see',\n",
       " 'star',\n",
       " 'fall',\n",
       " 'die',\n",
       " 'say',\n",
       " 'little',\n",
       " 'gretchen',\n",
       " 'grandma',\n",
       " 'good',\n",
       " 'little',\n",
       " 'girl',\n",
       " 'dead',\n",
       " 'grandma',\n",
       " 'say',\n",
       " 'star',\n",
       " 'fall',\n",
       " 'go',\n",
       " 'god',\n",
       " 'little',\n",
       " 'girl',\n",
       " 'light',\n",
       " 'match',\n",
       " 'big',\n",
       " 'light',\n",
       " 'gretchen',\n",
       " 'think',\n",
       " 'see',\n",
       " 'grandma',\n",
       " 'look',\n",
       " 'pretty',\n",
       " 'look',\n",
       " 'sweet',\n",
       " 'happy',\n",
       " 'go',\n",
       " 'o',\n",
       " 'grandma',\n",
       " 'say',\n",
       " 'little',\n",
       " 'girl',\n",
       " 'light',\n",
       " 'go',\n",
       " 'away',\n",
       " 'stove',\n",
       " 'turkey',\n",
       " 'christmas',\n",
       " 'tree',\n",
       " 'go',\n",
       " 'away',\n",
       " 'gretchen',\n",
       " 'light',\n",
       " 'bunch',\n",
       " 'match',\n",
       " 'want',\n",
       " 'grandma',\n",
       " 'match',\n",
       " 'light',\n",
       " 'grandma',\n",
       " 'take',\n",
       " 'little',\n",
       " 'girl',\n",
       " 'arm',\n",
       " 'go',\n",
       " 'cold',\n",
       " 'hungry',\n",
       " 'god',\n",
       " 'find',\n",
       " 'burn',\n",
       " 'dead',\n",
       " 'freeze',\n",
       " 'death',\n",
       " 'day',\n",
       " 'come',\n",
       " 'man',\n",
       " 'find',\n",
       " 'little',\n",
       " 'girl',\n",
       " 'street',\n",
       " 'dead',\n",
       " 'hand',\n",
       " 'burn',\n",
       " 'match',\n",
       " 'say',\n",
       " 'poor',\n",
       " 'little',\n",
       " 'thing',\n",
       " 'freeze',\n",
       " 'death',\n",
       " 'know',\n",
       " 'happy',\n",
       " 'heaven',\n",
       " 'little',\n",
       " 'red',\n",
       " 'riding',\n",
       " 'hood',\n",
       " 'cake',\n",
       " 'coat',\n",
       " 'butter',\n",
       " 'basket',\n",
       " 'hood',\n",
       " 'year',\n",
       " 'old',\n",
       " 'grandma',\n",
       " 'red',\n",
       " 'coat',\n",
       " 'hood',\n",
       " 'look',\n",
       " 'pretty',\n",
       " 'child',\n",
       " 'call',\n",
       " 'red',\n",
       " 'riding',\n",
       " 'hood',\n",
       " 'day',\n",
       " 'mama',\n",
       " 'say',\n",
       " 'want',\n",
       " 'cake',\n",
       " 'butter',\n",
       " 'grandma',\n",
       " 'red',\n",
       " 'riding',\n",
       " 'hood',\n",
       " 'glad',\n",
       " 'good',\n",
       " 'time',\n",
       " 'grandma',\n",
       " 'little',\n",
       " 'red',\n",
       " 'riding',\n",
       " 'hood',\n",
       " 'mother',\n",
       " 'thing',\n",
       " 'little',\n",
       " 'basket',\n",
       " 'run',\n",
       " 'wolf',\n",
       " 'mill',\n",
       " 'shall',\n",
       " 'go',\n",
       " 'wood',\n",
       " 'red',\n",
       " 'riding',\n",
       " 'hood',\n",
       " 'come',\n",
       " 'wood',\n",
       " 'meet',\n",
       " 'big',\n",
       " 'wolf',\n",
       " 'meet',\n",
       " 'wolf',\n",
       " 'go',\n",
       " 'say',\n",
       " 'wolf',\n",
       " 'red',\n",
       " 'riding',\n",
       " 'hood',\n",
       " 'say',\n",
       " 'go',\n",
       " 'grandma',\n",
       " 'mama',\n",
       " 'cake',\n",
       " 'butter',\n",
       " 'live',\n",
       " 'far',\n",
       " 'say',\n",
       " 'wolf',\n",
       " 'yes',\n",
       " 'say',\n",
       " 'red',\n",
       " 'riding',\n",
       " 'hood',\n",
       " 'white',\n",
       " 'house',\n",
       " 'mill',\n",
       " 'shall',\n",
       " 'say',\n",
       " 'wolf',\n",
       " 'short',\n",
       " 'flower',\n",
       " 'soft',\n",
       " 'stop',\n",
       " 'tap',\n",
       " 'pull',\n",
       " 'pick',\n",
       " 'voice',\n",
       " 'string',\n",
       " 'wolf',\n",
       " 'run',\n",
       " 'take',\n",
       " 'short',\n",
       " 'way',\n",
       " 'red',\n",
       " 'riding',\n",
       " 'hood',\n",
       " 'stop',\n",
       " 'pick',\n",
       " 'flower',\n",
       " 'wolf',\n",
       " 'get',\n",
       " 'house',\n",
       " 'tap',\n",
       " 'door',\n",
       " 'grandma',\n",
       " 'say',\n",
       " 'wolf',\n",
       " 'voice',\n",
       " 'soft',\n",
       " 'say',\n",
       " 'little',\n",
       " 'red',\n",
       " 'riding',\n",
       " 'hood',\n",
       " 'grandma',\n",
       " 'old',\n",
       " 'lady',\n",
       " 'say',\n",
       " 'pull',\n",
       " 'string',\n",
       " 'door',\n",
       " 'open',\n",
       " 'wolf',\n",
       " 'pull',\n",
       " 'string',\n",
       " 'door',\n",
       " 'open',\n",
       " 'run',\n",
       " 'eat',\n",
       " 'poor',\n",
       " 'old',\n",
       " 'lady',\n",
       " 'jump',\n",
       " 'bed',\n",
       " 'cap',\n",
       " 'tap',\n",
       " 'thank',\n",
       " 'dear',\n",
       " 'arm',\n",
       " 'hug',\n",
       " 'call',\n",
       " 'red',\n",
       " 'riding',\n",
       " ...]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.Corpus[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from unipath import Path\n",
    "wd = os.getcwd()\n",
    "p = Path(wd)\n",
    "path = str(p.parent)\n",
    "\n",
    "# Saving Data for future analysis\n",
    "data.to_csv(path+'/Data/GuternsbergBooksClean.csv', header=True, index=False, encoding='utf-8')\n",
    "#data.to_csv(path+\"/Data/MovieReviewsWithSentimentsClean.csv\", header=True, index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": {
       "Software versions": [
        {
         "module": "Python",
         "version": "3.6.8 64bit [GCC 7.3.0]"
        },
        {
         "module": "IPython",
         "version": "7.2.0"
        },
        {
         "module": "OS",
         "version": "Linux 4.15.0 46 generic x86_64 with debian buster sid"
        },
        {
         "module": "pandas",
         "version": "0.22.0"
        },
        {
         "module": "numpy",
         "version": "1.16.2"
        },
        {
         "module": "requests",
         "version": "2.21.0"
        },
        {
         "module": "bs4",
         "version": "4.7.1"
        },
        {
         "module": "selenium",
         "version": "3.141.0"
        },
        {
         "module": "lxml",
         "version": "4.3.2"
        },
        {
         "module": "urllib3",
         "version": "1.24.1"
        },
        {
         "module": "pyvirtualdisplay",
         "version": "0.2.1"
        },
        {
         "module": "unipath",
         "version": "1.1"
        }
       ]
      },
      "text/html": [
       "<table><tr><th>Software</th><th>Version</th></tr><tr><td>Python</td><td>3.6.8 64bit [GCC 7.3.0]</td></tr><tr><td>IPython</td><td>7.2.0</td></tr><tr><td>OS</td><td>Linux 4.15.0 46 generic x86_64 with debian buster sid</td></tr><tr><td>pandas</td><td>0.22.0</td></tr><tr><td>numpy</td><td>1.16.2</td></tr><tr><td>requests</td><td>2.21.0</td></tr><tr><td>bs4</td><td>4.7.1</td></tr><tr><td>selenium</td><td>3.141.0</td></tr><tr><td>lxml</td><td>4.3.2</td></tr><tr><td>urllib3</td><td>1.24.1</td></tr><tr><td>pyvirtualdisplay</td><td>0.2.1</td></tr><tr><td>unipath</td><td>1.1</td></tr><tr><td colspan='2'>Sat Apr 13 00:05:29 2019 CDT</td></tr></table>"
      ],
      "text/latex": [
       "\\begin{tabular}{|l|l|}\\hline\n",
       "{\\bf Software} & {\\bf Version} \\\\ \\hline\\hline\n",
       "Python & 3.6.8 64bit [GCC 7.3.0] \\\\ \\hline\n",
       "IPython & 7.2.0 \\\\ \\hline\n",
       "OS & Linux 4.15.0 46 generic x86\\_64 with debian buster sid \\\\ \\hline\n",
       "pandas & 0.22.0 \\\\ \\hline\n",
       "numpy & 1.16.2 \\\\ \\hline\n",
       "requests & 2.21.0 \\\\ \\hline\n",
       "bs4 & 4.7.1 \\\\ \\hline\n",
       "selenium & 3.141.0 \\\\ \\hline\n",
       "lxml & 4.3.2 \\\\ \\hline\n",
       "urllib3 & 1.24.1 \\\\ \\hline\n",
       "pyvirtualdisplay & 0.2.1 \\\\ \\hline\n",
       "unipath & 1.1 \\\\ \\hline\n",
       "\\hline \\multicolumn{2}{|l|}{Sat Apr 13 00:05:29 2019 CDT} \\\\ \\hline\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "Software versions\n",
       "Python 3.6.8 64bit [GCC 7.3.0]\n",
       "IPython 7.2.0\n",
       "OS Linux 4.15.0 46 generic x86_64 with debian buster sid\n",
       "pandas 0.22.0\n",
       "numpy 1.16.2\n",
       "requests 2.21.0\n",
       "bs4 4.7.1\n",
       "selenium 3.141.0\n",
       "lxml 4.3.2\n",
       "urllib3 1.24.1\n",
       "pyvirtualdisplay 0.2.1\n",
       "unipath 1.1\n",
       "Sat Apr 13 00:05:29 2019 CDT"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%load_ext version_information\n",
    "%version_information pandas, numpy, requests, bs4, selenium, lxml, urllib3, pyvirtualdisplay, unipath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
